{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import  tensor_train\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.linalg as linalg\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "tl.set_backend('numpy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tt3d:\n",
    "    def __init__(self):\n",
    "        self.cores = None\n",
    "        self.fitted = False\n",
    "    \n",
    "    def fit(self,tensor):\n",
    "        tensor = tl.tensor(tensor)\n",
    "        self.cores = tensor_train(tensor, [1, len(tensor[:,0,0]), len(tensor[0,:,0]), 1])\n",
    "        #for i,core in enumerate(self.cores):\n",
    "         #   print(f\"index = {i} shape = {core.shape}\")\n",
    "    \n",
    "    def predict(self,person):\n",
    "        [G1, G2, G3] = self.cores\n",
    "        G1 = G1[0,:,:]\n",
    "        G3 = G3[:,:,0]\n",
    "        z_k = np.dot(G1.T , person)\n",
    "        [_,ne, _] = G2.shape\n",
    "        min_e = 1e10\n",
    "        min_p = 1e10\n",
    "        min_DTT = 1e10\n",
    "        for e in range(ne):\n",
    "            G2_e = G2[:,e,:]\n",
    "            Q,R = np.linalg.qr(G2_e,mode=\"reduced\")\n",
    "            alfa_e = np.dot(Q.T,z_k)\n",
    "            alfa_e = linalg.solve(R, alfa_e)\n",
    "            for p in range(len(G3[0,:])):\n",
    "                norm = linalg.norm(alfa_e - G3[:,p],2)\n",
    "                if(norm < min_DTT):\n",
    "                    #print(f\"e = {e} , p = {p} , norm = {linalg.norm(alfa_e - G3[:,p],2)}\")\n",
    "                    min_DTT = norm\n",
    "                    min_e = e\n",
    "                    min_p = p\n",
    "    \n",
    "        return(min_e,min_p)\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tt4d:\n",
    "    def __init__(self):\n",
    "        self.cores = None\n",
    "        self.fitted = False\n",
    "    \n",
    "    def fit(self,tensor):\n",
    "        tensor = tl.tensor(tensor)\n",
    "        self.cores = tensor_train(tensor, [1, len(tensor[:,0,0,0]), len(tensor[0,0,:,0])*len(tensor[0,0,0,:]), len(tensor[0,0,0,:]), 1])\n",
    "        #for i,core in enumerate(self.cores):\n",
    "         #   print(f\"index = {i} shape = {core.shape}\")\n",
    "    \n",
    "    def predict(self,z):\n",
    "        [G1, G2, G3, G4] = self.cores\n",
    "        z = z.flatten()\n",
    "        G12 = tl.tenalg.mode_dot(G2,G1[0,:,:],0)\n",
    "        G4 = G4[:,:,0]\n",
    "        [_,ne, _] = G3.shape\n",
    "        min_e = 1e10\n",
    "        min_p = 1e10\n",
    "        min_DTT = 1e10\n",
    "        for e in range(ne):\n",
    "            C_e = tl.tenalg.mode_dot(G12, G3[:,e,:].T,2)\n",
    "            alfa_e = linalg.lstsq(tl.base.unfold(C_e, 2).T, z)\n",
    "            alfa_e = alfa_e[0]\n",
    "            for p in range(len(G4[0,:])):\n",
    "                norm = linalg.norm(alfa_e - G4[:,p],2)\n",
    "                if(norm < min_DTT):\n",
    "                    #print(f\"e = {e} , p = {p} , norm = {linalg.norm(alfa_e - G4[:,p],2)}\")\n",
    "                    min_DTT = norm\n",
    "                    min_e = e\n",
    "                    min_p = p\n",
    "    \n",
    "        return(min_e,min_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORL Tensor Shape (Pixels, Expressions, Persons): (10304, 10, 40)\n",
      "Labels Shape: (10, 40)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_orl_tensor3d(dataset_path):\n",
    "    num_persons = 40\n",
    "    num_expressions = 10\n",
    "    img_size = (92, 112)  \n",
    "    img_vector_size = img_size[0] * img_size[1]  \n",
    "\n",
    "    orl_tensor = np.zeros((img_vector_size, num_expressions, num_persons))\n",
    "    labels = np.zeros((num_expressions, num_persons), dtype=int)  \n",
    "\n",
    "    for person_id in range(1, num_persons + 1):\n",
    "        person_folder = os.path.join(dataset_path, f\"s{person_id}\")\n",
    "\n",
    "        for img_id in range(1, num_expressions + 1):\n",
    "            img_path = os.path.join(person_folder, f\"{img_id}.pgm\")\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  \n",
    "            \n",
    "            img_vector = img.flatten()\n",
    "\n",
    "            orl_tensor[:, img_id - 1, person_id - 1] = img_vector\n",
    "            labels[img_id - 1, person_id - 1] = person_id - 1 \n",
    "\n",
    "    return tl.tensor(orl_tensor), labels\n",
    "\n",
    "dataset_path = r\"C:\\\\Users\\\\grgos\\\\Downloads\\\\matricne\\\\archive\"\n",
    "\n",
    "orl_tensor3d, orl_labels = load_orl_tensor3d(dataset_path)\n",
    "\n",
    "print(\"ORL Tensor Shape (Pixels, Expressions, Persons):\", orl_tensor3d.shape)\n",
    "print(\"Labels Shape:\", orl_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 25)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = tt3d()\n",
    "temp.fit(orl_tensor3d)\n",
    "temp.predict(orl_tensor3d[:,4,25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORL Tensor Shape (Pixels, Expressions, Persons): (112, 92, 10, 40)\n",
      "Labels Shape: (10, 40)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_orl_tensor4d(dataset_path):\n",
    "    num_persons = 40\n",
    "    num_expressions = 10\n",
    "    img_size = (92, 112)  \n",
    "\n",
    "    orl_tensor = np.zeros((img_size[1], img_size[0], num_expressions, num_persons))\n",
    "    labels = np.zeros((num_expressions, num_persons), dtype=int)  \n",
    "\n",
    "    for person_id in range(1, num_persons + 1):\n",
    "        person_folder = os.path.join(dataset_path, f\"s{person_id}\")\n",
    "\n",
    "        for img_id in range(1, num_expressions + 1):\n",
    "            img_path = os.path.join(person_folder, f\"{img_id}.pgm\")\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  \n",
    "            \n",
    "\n",
    "            orl_tensor[:,:, img_id - 1, person_id - 1] = img[:,:]\n",
    "            labels[img_id - 1, person_id - 1] = person_id - 1 \n",
    "\n",
    "    return tl.tensor(orl_tensor), labels\n",
    "\n",
    "dataset_path = r\"C:\\\\Users\\\\grgos\\\\Downloads\\\\matricne\\\\archive\"\n",
    "\n",
    "orl_tensor4d, orl_labels = load_orl_tensor4d(dataset_path)\n",
    "\n",
    "print(\"ORL Tensor Shape (Pixels, Expressions, Persons):\", orl_tensor4d.shape)\n",
    "print(\"Labels Shape:\", orl_labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 39)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp4d = tt4d()\n",
    "temp4d.fit(orl_tensor4d)\n",
    "temp4d.predict(orl_tensor4d[:,:,8,39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 7, 0, 4, 8, 3, 6, 5, 2, 9]\n",
      "0.9\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "x = list(range(0, 10))\n",
    "random.shuffle(x)\n",
    "print(x)\n",
    "test_split =x[:2]\n",
    "train_split = x[2:]\n",
    "orl_tensor3d_train = orl_tensor3d[:,train_split,:]\n",
    "orl_tensor3d_test = orl_tensor3d[:,test_split,:]\n",
    "test3d = tt3d()\n",
    "test3d.fit(orl_tensor3d_train)\n",
    "num = 0\n",
    "for i in range(2):\n",
    "    for j in range(40):\n",
    "        output = test3d.predict(orl_tensor3d_test[:,i,j])\n",
    "        if output[1] == j:\n",
    "            num += 1\n",
    "print(num / 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 0, 6, 7, 5, 9, 1, 3, 4, 8]\n",
      "0.975\n"
     ]
    }
   ],
   "source": [
    "x = list(range(0, 10))\n",
    "random.shuffle(x)\n",
    "print(x)\n",
    "test_split =x[:2]\n",
    "train_split = x[2:]\n",
    "orl_tensor4d_train = orl_tensor4d[:,:,train_split,:]\n",
    "orl_tensor4d_test = orl_tensor4d[:,:,test_split,:]\n",
    "test4d = tt4d()\n",
    "test4d.fit(orl_tensor4d_train)\n",
    "num = 0\n",
    "for i in range(2):\n",
    "    for j in range(40):\n",
    "        output = test4d.predict(orl_tensor4d_test[:,:,i,j])\n",
    "        if output[1] == j:\n",
    "            num += 1\n",
    "print(num / 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COIL Tensor Shape (Pixels, Expressions, Persons): (16384, 72, 20)\n"
     ]
    }
   ],
   "source": [
    "def load_coil_tensor3d(dataset_path):\n",
    "    num_persons = 20\n",
    "    num_expressions = 72\n",
    "    img_size = (128, 128)  \n",
    "    img_vector_size = img_size[0] * img_size[1]  \n",
    "\n",
    "    coil_tensor = np.zeros((img_vector_size, num_expressions, num_persons))\n",
    "\n",
    "    for person_id in range(1, num_persons + 1):\n",
    "        person_folder = os.path.join(dataset_path, f\"{person_id}\")\n",
    "        #print(person_folder)\n",
    "\n",
    "        for img_id in range(0, num_expressions):\n",
    "            img_path = os.path.join(person_folder, f\"obj{person_id}__{img_id}.png\")\n",
    "        #   print(img_path)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  \n",
    "            \n",
    "            img_vector = img.flatten()\n",
    "\n",
    "            coil_tensor[:, img_id - 1, person_id - 1] = img_vector\n",
    "\n",
    "    return tl.tensor(coil_tensor)\n",
    "\n",
    "dataset_path = r\"C:\\\\Users\\\\grgos\\\\Downloads\\\\matricne\\\\archive_coil20\\\\coil-20\"\n",
    "\n",
    "coil_tensor3d = load_coil_tensor3d(dataset_path)\n",
    "\n",
    "print(\"COIL Tensor Shape (Pixels, Expressions, Persons):\", coil_tensor3d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 5, 34, 47, 67, 4, 50, 36, 13, 20, 10, 40, 24, 8, 11, 46, 55, 68, 27, 18, 31, 44, 1, 43, 14, 54, 70, 17, 0, 42, 65, 51, 19, 35, 21, 52, 16, 29, 71, 2, 33, 61, 6, 32, 41, 25, 45, 28, 22, 15, 57, 60, 62, 69, 39, 7, 23, 59, 30, 26, 63, 58, 12, 66, 3, 9, 48, 53, 64, 38, 56, 37]\n",
      "0.9928571428571429\n"
     ]
    }
   ],
   "source": [
    "x = list(range(0, 72))\n",
    "random.shuffle(x)\n",
    "print(x)\n",
    "test_split =x[:14]\n",
    "train_split = x[14:]\n",
    "coil_tensor3d_train = coil_tensor3d[:,train_split,:]\n",
    "coil_tensor3d_test = coil_tensor3d[:,test_split,:]\n",
    "test3d = tt3d()\n",
    "test3d.fit(coil_tensor3d_train)\n",
    "num = 0\n",
    "for i in range(14):\n",
    "    for j in range(20):\n",
    "        output = test3d.predict(coil_tensor3d_test[:,i,j])\n",
    "        if output[1] == j:\n",
    "            num += 1\n",
    "print(num / (20*14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COIL Tensor Shape (Pixels, Expressions, Persons): (128, 128, 72, 20)\n"
     ]
    }
   ],
   "source": [
    "def load_coil_tensor4d(dataset_path):\n",
    "    num_persons = 20\n",
    "    num_expressions = 72\n",
    "    img_size = (128, 128)  \n",
    "    img_vector_size = img_size[0] * img_size[1]  \n",
    "\n",
    "    coil_tensor = np.zeros((128,128, num_expressions, num_persons))\n",
    "\n",
    "    for person_id in range(1, num_persons + 1):\n",
    "        person_folder = os.path.join(dataset_path, f\"{person_id}\")\n",
    "        #print(person_folder)\n",
    "\n",
    "        for img_id in range(0, num_expressions):\n",
    "            img_path = os.path.join(person_folder, f\"obj{person_id}__{img_id}.png\")\n",
    "        #   print(img_path)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  \n",
    "            \n",
    "            #img_vector = img.flatten()\n",
    "\n",
    "            coil_tensor[:,:, img_id - 1, person_id - 1] = img[:,:]\n",
    "\n",
    "    return tl.tensor(coil_tensor)\n",
    "\n",
    "dataset_path = r\"C:\\\\Users\\\\grgos\\\\Downloads\\\\matricne\\\\archive_coil20\\\\coil-20\"\n",
    "\n",
    "coil_tensor4d = load_coil_tensor4d(dataset_path)\n",
    "\n",
    "print(\"COIL Tensor Shape (Pixels, Expressions, Persons):\", coil_tensor4d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 66, 61, 68, 27, 58, 55, 57, 29, 11, 45, 0, 65, 50, 46, 12, 25, 26, 21, 8, 4, 62, 34, 71, 49, 1, 40, 5, 70, 17, 33, 6, 64, 60, 63, 2, 47, 24, 52, 56, 23, 16, 32, 67, 36, 38, 15, 3, 28, 69, 19, 48, 42, 14, 37, 30, 35, 18, 31, 54, 51, 22, 41, 43, 44, 53, 9, 39, 13, 20, 59, 10]\n",
      "0.9964285714285714\n"
     ]
    }
   ],
   "source": [
    "x = list(range(0, 72))\n",
    "random.shuffle(x)\n",
    "print(x)\n",
    "test_split =x[:14]\n",
    "train_split = x[14:]\n",
    "coil_tensor4d_train = coil_tensor4d[:,:,train_split,:]\n",
    "coil_tensor4d_test = coil_tensor4d[:,:,test_split,:]\n",
    "test4d = tt4d()\n",
    "test4d.fit(coil_tensor4d_train)\n",
    "num = 0\n",
    "for i in range(14):\n",
    "    for j in range(20):\n",
    "        output = test4d.predict(coil_tensor4d_test[:,:,i,j])\n",
    "        if output[1] == j:\n",
    "            num += 1\n",
    "print(num / (20*14))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
